# Definitionen
## Maschienenschnittstelle, Instruction Set Architecture (ISA)
- ISA ist Befehlsatz eines Prozessors
	- -> die Menge der Maschinenbefehle
- Unterscheidung zwischen RISC- (Reduced Instruction Set Computer) und CISC- (Complex Instruction Set Computer) Architekturen

## Assembler (Sprache)
- Ist einen maschienennahe (konkrete) Programmiersprache
- an die ISA der Zielarchitektur angelehnt
- Durch Verwendung von Namen und symbolischen Adressen wird die Nutzung der ISA vereinfacht

## Assembler (Programm)
- Systemprogramm, dass
	- Assemblerbefehle in Maschinencode transformiert und 
	- Symbolischen Namen Maschienenadressen zuweist und ein Objektprogramm erzeugt

#gbs/def Maschienenschnittstelle, ISA, Assembler 

# Vom Quellcode zum Programm
- Quellcode
	- bindet ggf weitere libraries mittels header
- Compiler
	- Preprocessor
		- bindet Dateien von header in code ein
	- Compiler
		- übersetzt von C in Assembler
- Assembler
	- Übersetzt von Maschinensprache in die ISA
- Linker (Binder) 
	- einzelne Module binden
	- produziert ELF Datei 
		- Executable linkable format
		- beginnt mit "7f" im hex Darstellung
- Loader (BS)
	- Liest ELF und lädt die Objekte in den zugehörigen Speicher


![[Pasted image 20251219121318.png|575]]

# [[GBS/1. Einführung#Prozesse|Prozesse]]

## Prozessor
![[Pasted image 20251219121940.png|500]]
- IOPL
	- in welchem betriebsmodus sich der prozessor gerade befindet
	- 2 bits -> [0, 3] darstellbar
	- verschiedene modus mit nummerierung 0-3

## Prozess im speicher
- code segment
	- read only da code unverändert sein soll
- data segment 
	- rodata
		- static constants
	- data
		- static local variablen
		- globale variablen im heap
	- heap
		- dynamically allocated
- stack segment
	- base pointer -> Anfang von jedem aufgerufenen Fkt (alte pos wird gemerkt)
		- stack frame ist von bp zu sp für jede Fkt
	- stack pointer -> wird verschoben jedes mal eine variable drauf geschoben wird
	- wächst von oben nach unten
	- lokale variblen
	- fktaufruf
	- mittlerweile fkt param nicht mehr auf den stack -> register 
- ![[Pasted image 20251219123451.png|525]]


## Prozesskontext im BS
- Abbild der CPU muss hinterlegt werden wenn einem prozess die CPU "weggenommen" wird -> bestimmte Datenstruktur

![[Pasted image 20251219123843.png|525]]
![[Pasted image 20251219123938.png|500]]

## Parallele Prozesse, Multiprogramming 
- System ist Menge von Prozessen
	- Prozesse können (quasi) parallel verarbeitet werden
	- Wechseln zwischen verschiedenen Prozessen (Scheduling)

> Warum Multiprogramming? 
- Prozesse können limitiert sein 
	- I/O bound
	- CPU bound
- -> Proz wechseln während man wartet

### Prozess-Zustände
> Zustände
- rechenwillig/ready
- rechnend/running
- wartend/blocked
- ausgelagert/swapped out

![[Pasted image 20251219124604.png|550]]
> Zustandsübergänge
- add
	- (init) -> ready
	- neu erzeigter Prozess wird zu der Menge der rechenwilligen Prozesse hinzugefügt
- assign
	- ready, running
	- als Folge eines Kontextwechsels wird dem Prozess die CPU zugeordner
- block
	- running -> blocked
	- aufgrund eines I/O-Aufrufs oder einer Synchronisationsoperation wird der Prozess auf wartend gesetzt
- ready
	- blocked -> ready 
	- nach Beendigung der angestoßenen Operation wechselt der Prozess in den Zustand rechenwillig
- retire
	- running -> (terminated)
	- der aktuell rechende Prozess terminiert
- swap out 
	- anywhere -> swapped out
	- Prozess wird auf die Festplatte ausgelagert
- swap in
	- swapped out -> ready/blocked
	- ausgelagerter Prozess wird in den Speicher gebracht

# Thread
- ein Thread wird betrachtet als eine Abstraktion eines physischen Prozessors
- repräsentieren nebenläufige Ausführungspfade eines Rechensystems
- Prozess besitzt mindestens einen Thread
- Multi-Threaded-Prozess besitzt mehrere Kontrollflüsse
- Threads eines Prozesses teilen sich dessen Adressraum
- Jeder Thread besitzt seinen eigenen Befehlszähler(instruction pointer)

![[Pasted image 20251219160838.png|400]]

#gbs/def 

# Prozess vs. Thread

- Prozess ist Programm in Ausführung
	- Benutzt Ressouren
	- Hat einen Kontrollfluss (definiert durch die Instruktion des Programms)
		- Ressourcen: CPU, Speicher etc
		- Kontrollfluss: Programmlogik, Schleifen, Bedingungen, Reihenfolge
- Prozess gruppiert und verwaltet Ressourcen
	- Adressraum inkl. Programmcode und Daten
	- Gemeinsam nutzbare Ressourcen für alle Threads eines Prozesses
- Thread definiert einen Kontrollfluss

- Thread-Kontext muss gesichert werden, sobald einem Thread die CPU entzogen wird (running -> blocked/ready)
	- program counter/instruction pointer
	- Registerwerte (z.B. Variablen etc.)
	- Stack zur Verwaltung von Unterprogrammaufrufen

| Per-process items                                                                                                                             | Per-thread items                               |
| --------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------- |
| Address space<br>Global variables<br>Open files<br>Child processes<br>Pending alarms<br>Signals and signal handlers<br>Accounting information | Program counter<br>Registers<br>Stack<br>State |
- Threads sind Aktivitätsträger
- Threads können auch in verschiedenen Zuständen sein (rechenwillig, rechnend, wartend, terminiert)
- ![[Pasted image 20251219161235.png|500]]


# Multi-Threading
## Warum? 
> Overhead
- Thread ist ein "lightweight" Prozess 
	- -> u.a. gemeinsamer Adressraum
- Einfache Kommunikation zwischen Threads eines Prozesses über gemeinsamen Adressraum
- Aufwand, einen Thread innerhalb eines Prozesses zu erstellen, ist wesentlich geringer als einen Prozess zu erzeugen
- Threads können wesentlich schneller ihren Kontext wechseln

> Performance
- Multi-Threading ermöglicht die quasi-parallele Ausführung von I/O-intensiven und CPU-intensiven Bereichen eines Prozesses
- Echt parallele Ausführung von Threads auf mehreren CPUs/Cores

## Beispiel: Multi-threaded Web-Server
- Ein Dispatcher-Thread erstellt auf Anfragen neue Server-Threads
- Mehrere Server-Threads (dynamisch erzeugt) bearbeiten eine Anfrage
- ![[Pasted image 20260201165453.png|525]]

- Dispatcher-Thread code:
```c
while (TRUE) {
	get_next_request (&buf);
	handoff_request (&buf);
}
```

- Worker-Threads code:
```c
while (TRUE) {
	wait_for_work (&buf);
	look_for_page_in_cache (&buf, &page);
	if (page_not_in_cache (&page));
		read_page_from_disk (&buf, &page);
	return_page (&page);
}
```


# Implementierung von Prozessen
- Kernel-Datenstruktur: **==Prozess Control Block==** (PCB)
	- Informationen für die ==Prozessverwaltung== (engl. process management)
		- Registerinhalte (inkl. Programm Counter, Stack Pointer, Statusregister (Flags), etc)
		- Prozess Zustand (z.B. wartent, rechnend, etc.)
			- Rechnend: Angabe der zugehörigen CPU
			- Wartend: Angabe des Ereignisses, auf das der Prozess wartet
		- Priorität
		- Eindeutige Process ID (PID)
		- Paren PID (PPID), Identität des Eltern-Prozesses
		- Process Group ID (PGID)
	
	- Informationen für die ==Speicherverwaltung== (memory management)
		- Pointer zu Code-, Daten-, und Stack-Segment
			- Beinhalten Angang und Größe der entsprechenden Segmente
	
	- Informationen für die ==Dateiverwaltung== (file management)
		- Root Verzeichnis
		- File Descriptors: Datenstrukturen, die geöffnete Dateien beschreiben
		- Benutzer (User) und Gruppen ID (UID, GID)

- Betriebssystem verwaltet alle Prozesse in Prozesstabellen
	- Eine Prozesstabelle ist eine verkettete Liste von PCBs
	- Separate Listen für die verschiedenen Prozesszustände
		- Run Queue: (Ready Queue) Linux rechenwillige Prozesse
		- Wait Queue: Verwaltet unter Linux wartende Prozesse
	- ![[Pasted image 20260201171239.png|550]]

## Prozesshierarchien (Unix)
- Nach Initialisierung aller Subsysteme des Kernels wird der erste Userspace-Process init erzeugt
- init erstellt einen Login-Prozess pro "Terminal", der das Einloggen ermöglicht
- der Login-Prozess erzeugt eine Shell, die wiederum weitere Prozesse erzeugen kann
- Jeder Prozess inkl seiner Kinder formen eine ==Prozessgruppe== (durch die PGID gekennzeichnet)
- Der Eltern-Prozess der Prozessgruppe bildet dabei den Prozessgruppen-Leader
- ![[Pasted image 20260201181639.png|475]]
- Der Eltern-Prozess kann mit den Systemcalls `wait`oder `waitpid` darauf warten, dass der Kind-Prozess terminiert
	- der Eltern-Prozess blockiert (einfügen in die Wait-Queue), bis der Kind-Prozess terminiert
	- Nach der Beendigung des Kindes, kann der Elternprozess dne Grund der Terminierung erfragen

### Zombies
- Wenn der Kind- vor dem Eltern-Prozess terminiert, entsteht ein sog. Zombie-Prozess
- Wenn ein Kind-Prozess so terminiert, dann wird
	- der Speicher des Prozesses de-allokiert und
	- der Exit-Status in den PCB geschrieben und bleibt erhalten: Zombie
- Sobald der Elternprozess den Exit-Status mit `wait(waitpid)` gelesen hat, wird der Zombie entfernt
- Zombie-Prozesse führen keinen Code mehr aus, belegen aber noch Platz in der Prozess-Tabelle

### Waisen
- orphans entstehen, wenn der Eltern- vor dem Kind-Prozess terminiert 
	- Kind-Prozess wird dann vom Init-Prozess adoptiert: PPID = 1
- Ein Waisen-Prozess kann anschließend zum Dämonen (Hintergrundprozess) werden
	- Dafür muss der Prozess sich von der Gruppen-ID und Benutzer-ID lösen
	- Gegebenenfalls alle offenen Filedeskriptoren (stdin, stdout, stderr) umleiten

>Bei Windows gibt es keine Prozesshierarchien
- Jedem Prozess wird bei Erzeugung ein Handle zugeordnet
- Kann an andere Prozesse übergeben werden

# BS-Dienste zur Prozessverwaltung
## zur Erzeugung von Prozessen
### Auslöser
> während der Systeminitialisierung
- Erzeugung von Vordergrundprozessen
	- Interagieren mit dem Benutzer
- von Hintergrundprozessen
	- Dämonen (daemons), spezielle Systemprozesse
	- Langlebige, passive Sysprozesse, die durch Ereignisse aktiviert werden

> durch andere Prozesse
- Auslagerung der Arbeit auf mehrere Prozesse 
- Beispiel: Server erzeugt für jede Client-Anfrage einen neuen Prozess

> durch Benutzer
- Ausführung eines Kommandos in der Shell; Doppelklick auch ein Icon

> durch das BS (Batch-Systeme)
- BS erstellt neue Prozesse, um eine Menge von Aufgaben oder Daten zu verarbeiten

### Dienste
- POSIX-Syscall: `pid_t fork()`
	- Eltern-Prozess erzeugt exakte Kopie (Kind-Prozess) inkl. Code, Data
	- Kopie des Speicherabbildes des Elternprozesses
		- Ausnahme copy-on-write (COW) Memory
	- Jeder Prozess erhält bei Erzeugung eine PID
	- Rückgabewert von fork unterscheidet Eltern- und Kindprozess
		- Elternprozess erhält die PID des Kindprozesses als Ergebis
		- Kindprozess erhält den Wert 0
			- Prozess kann die eigene PID erfragen mittels `getpid()`
			- Erfragen der PID des Elternprozesses mittels `getppid()`
	- Kind erbt unter anderem Filedeskriptoren zu offenen Dateien (z.B. stdin, stdout, stderr)
	- Falls der Kind-Prozess eigenen Code etc. benötige, so führt das Kind `exec{ve|le|...}` aus, um das Speichabbild zu überschreiben

- Beide Prozesse sind ==unabhängig== voneinander
	- Änderungen in einem nicht sichtbar für den anderen Prozess

## zur Terminierung von Prozessen
> Normale Beendigung (freiwillig)
- Das Programm terminiert durch das Aufrufen eines Systemcalls
- z.B. `void exit (int status), return status;` aus `main()`

> Vorzeitige Beendigung bei einem durch den Prozess erkannten Fehler (freiwillig)
- Beispiel: Das Programm erkennt, dass eine Datei nicht existiert
- Nutzung von `exit`wie obern, aber mit Fehlercode

> Vorzeitige Beendigung bei einem fatalem Fehler, erkannt durch das BS
- Verursacht durch einen Fehler im Programm
- Beispiel: Zugriff auf nicht existierenden Speicherbereich (Segmentation Fault)

> Terminierung durch einen anderen Prozess
- Beispiel: Senden einen Signals durch die Funktion `int kill (pid_t process_id, int signal);`

## Prozessorverwaltung
- Dispatcher: Realisiert Prozess-Zustandsübergänge von rechenwillig nach rechnend
	- die Ausführung von Prozess A muss unterbrochen werden, um die Ausführung eines anderen Prozesses B zu ermöglichen
- Scheduler: Wählt einen Prozess aus der Liste der rechenwilligen Prozesse (Run Queue)
	- Wahl des nächsten Prozesses durch Scheduling-Algorithmen getroffen
- ![[Pasted image 20260201184317.png|575]]

### Dispatcher
#### Aufgaben (meist Bestandteil des Schedulers)
- Bei den Zustandübergängen zwischen rechnend und rechenwillig finden Kontextwechsel (context switch) statt
- der Dispatcher implementiert den Wechsel
- Dispatcher entzieht den rechenden Prozess/Thread die CPU und teilt sie einem anderen rechenbereitem Prozess/Thread zu

1. **Ändert den Zustand** des rechenden Prozesses zu wartend oder rechenbereit
2. **Sichert den Kontext** des zuvor rechnenden Prozesses/Threads im PCB
3. **Lädt den Kontext** des rechenbereiten Prozesses/Threads
4. **Ändert den Zustand** des rechenbereiten Prozesses zu rechnend

![[Pasted image 20260201185337.png|425]]

- Beachte: Je umfangreicher ein PCB, desto teurer (d.h. aufwendiger) sind Kontextwechsel
- Threads haben einen kleineren Kontext im Vergleich zu Prozessen
	- Erinnerung: Prozesse gruppieren Ressourcen
	- Threads teilen sich Ressourcen mit dem Prozess (u.a. Adressraum)
- Ein Umschalten zwischen Threads ==im gleichen Prozess== erfolgt deshalb sehr schnell
- Wechseln zwischen Threads ==verschiedener Prozesse== ist genauso teuer wie ein Prozess-Wechsel

### Scheduler
- Treffen von strategischen Entscheidungen
	- Wechen Prozess oder Thread, wann und wie lange an die CPU binden
	- bei Multiprozessor-Systemen muss zusätzlich entschieden werden, an welche CPU der Prozess gebunden wird
- Ausnutzen von typischem Prozessverhalten
	- CPU-Nutzungs-Bursts wechseln sich mit I/O-Wartephasen ab
	- Berücksichtigung von CPU-limitierten- und I/O-limitierten-Prozessen

- Der Scheduler wird bei nachfolgenden Ereignissen aktiv und muss Entscheidungen treffen
	- Wenn ein neuer Prozess erzeugt wird (fork)
		- Soll der Eltern- oder der Kind-Prozess ausgeführt werden? 
	- Wenn ein Prozess terminiert
		- Was passiert wenn kein rechenwilliger Prozess existiert? 
	- Wenn ein prozess blockiert (aufgrund von I/O, Semaphoren, etc.)
		- Was passiert, wenn der blockierende Prozess eine Ressource belegt und der nächste Prozess diese Ressource benötigt?
	- Wenn ein Interrupt auftritt
		- Ein Interrupt ausgehend von einem I/O-Device, kann einen blockierten Prozess aufwecken
		- Eine Scheduling-Entscheidung kann bei jedem Timer-Interrupt getroffen werden

# Implementierung von Threads
- Threads werden im Addressraum eines Prozesses ausgeführt
	- Verwenden Synchronisationsmechanismen, um koordiniert auf gemeinsame Ressourcen zuzugreifen (und diese zu "schützen")
- Analog zu Prozessen können Threads in den folgenden Zuständen sein
- Implementierungsvarianten von Threads
	- User Space
	- Kernel Space
	- Hybride Varianten
- ![[Pasted image 20260201195034.png|278]]
	- ganzer Block ist ein Prozess

## User-Level-Threads
- BS-Kern kennt keine Threads, sondern nur Prozesse 
	- der BS-Kern verwaltet Single-threaded-Prozesse
- Realisierung von Threads und deren Verwaltung erfordert zusätzliche Operationen
	- Implementierung mittles eines Thread-Pakets
	- Bibliothek im User-Space, die für die Thread-Verwaltung zuständig ist
	- Ein Thread-Paket setzt auf einem beliebigem BS auf
- Das Thread-Paket stellt als Laufzeitsystem eine Menge von Operationen zur Verfügung
	- thread_create, thread_exit, thread_join, thread_yield, etc
- Das Laufzeitsystem verwaltet Threads im User-Space
	- eine Threadtabelle für jeden Prozess
- Prozessorzuteilung im BS-Kern erfolgt an Prozesse
	- Dass Thread-Paket implementiert einen eigene Thread-Scheduler
	- D.h. das System implementiert ein Two-Level-Scheduling-Verfahren

### Scheduling
- BS kat keine Kenntnis von User-Level Threads
- Scheduler wählt einen Prozess aus und gibt diesem ein Quantim an CPU-Zeit
- Laufzeitsystem des Prozesses wählt einen rechenwilligen Thread des Prozesses aus
- Ein Thread kann vom Laufzeitsystem nicht unterbrochen werden
	- Aber Threads können selbst durch den Aufruf der Funktion thread_yield die CPU abgeben
- ![[Pasted image 20260201195451.png|500]]

### Vorteile
- BS-unabhängig
- umschalten zwischen verschiedenen Threads sehr effizient -> keine Syscalls
- anwendungsspezifisches Scheduling Algorithmen

### Nachteile
- Blockieren eines Threads -> Blockiert den Prozessor
- ein blockierender Syscall eines Threads kann blockiert den gesamten Prozess, da BS nur Prozess kennt und nicht die Threads -> Nebenläufigkeit kann also doch nicht erreicht werden
- Threads können die CPU monopolisieren

## Kernel-Level Threads
- BS-Kern verwaltet Threads selbst
	- Der BS-Kern hält eine Threadtabelle für alle Threads (im Kern)
	- Thread-Operationen führen zu einem Trap in den Kern
		- thread_create, thread_exit, etc.
		- Wechsel von User zu Kernel Mode
	- Systemaufrufe bei Erzeugung bzw. Terminierung von Threads
	- Nicht mehr so leichtgewichtig verglichen mit Prozessen
- ![[Pasted image 20260201202542.png|525]]

- BS-Scheduler wählt einen rechenwilligen Thread
- BS kontolliert die CPU Zuteilung an Threads

> Overhead minimieren
-  Scheduling-Entscheidungen: Kernel sollte die Thread-Zugehörigkeit zu Prozessen berücksichtigen, um den Overhead für einen Kontextwechsel zu verringern

> Blockierende I/O-Operationen
- Wenn ein Kernel-Level Thread blockiert, so kann die CPU einem anderen Thread des gleichen Prozesses zugeordnet werden, ohne den gesamten Prozess aufzuhalten

## Hybride Implementierung
- Der BS-Kern verwaltet sogenannte Kernel-Threads
- Das BS kennt nur Kernel-Threads: das Scheduling erfolgt für Kernel-Threads
- n Threads im User-Space werden auf m Kernel-Threads abgebildet (n:m Abbildung)
- ![[Pasted image 20260201203015.png|475]]

## Unix-Threads
- UNIX-basierte Systeme unterstützen Kernel-Level Threads

> LinuxThreads: Erste Thread Implementierung unter Linux
- Thread-Erzeugung mit dem Syscall `clone()`
- Threads teilen sich den Adressraum, Datei-Deskriptoren, Signale, etc.
- Jedoch besitzen alle Threads unterschiedliche PIDs und PPIDs
- Benötigen einen zusätzlichen Manager-Thread zur Erzeugung und Terminierung von Threads

> Native POSIX Thread Library (ab Linux kernel v2.6)
- Erweiterung des Syscalls clone (u.A. durch das Flag CLONE_THREAD)
- POSIX Thread Schnittstelle abstrahiert den Systemcall
- Implementiert eine 1:1 Abbildung von User-Space-Threads auf Kernel-Level Threads

> Beispiel: Java Threads (JVM Verwendet NPTL)
- Jeder Java-Thread gehört dem Java-Virtual-Machine Prozess an
- Jeder Java Thread wird 1:1 auf einen Kernel-Level-Thread abgebidet

## Beispiel: Thread-Erzeugung unter Linux
- Der Main-Thread erstellt einen zweiten Thread mit `pthread_create`
	- Der neue Thread führt die übergebene Funktion `thread_func` aus
	- Der String "hello world" wird `thread_func` als Argument übergeben

- Der erzeugte THread führt die Funktion aus und beendet sich mit `pthread_exit` 
	- Alternativ, kann der Rückgabewert auch mit return übergeben werden
	- Achtung: Ausführen von `exit` beendet den gesamten Prozess

- `pthread_join` wartet auf die Terminierung und Rückgabewert des Threads
	- Andernfalls entsteht ein Pendant zu einem Zombie-Prozess

# Linux: Prozesse vs. Threads
- Linux nutzt ein gemeinsames Basiskonstrukt: "Tasks"
	- Tasks sind Instanzen, die von Scheduler gesteuert werden

- Prozesse und Threads werden beide auf Tasks abgebildet
	- Linux realisiert Kernel-Level Threads

- Unterscheidung zwischen Prozessen und Threads durch den Grad der Isolation voneinander bzw. der gemeinsamen Nutzung von Ressourcen
	- Parameter steuern, welche Ressourcen sich zwei Tasks teilen 
	- Individuell für verschiedene Ressourcen einstellbar
	
	- Extrem 1: keine geteilten Ressourcen -> Prozesse
	- Extrem 2: quasi alle Ressourcen geteilt -> Threads

- `fork()` und `pthread_create()` werden auf denselben Syscall abgebildet: `clone()`
	- u.A. Flags als Parameter für clone
		- CLONE_FILES - file descriptor table
		- CLONE_FS - file system (e.g. working directory, umask)
		- CLONE_IO - IO context (SDD/HDD Zugriff)
		- CLONE_PARENT - gleicher Elternprozess
		- CLONE_PID - gleiche PID
		- CLONE_VM - virtueller Speicher
		- CLONE_NEW - unabhängige Namensräume


# Scheduling
- Vergabe der CPU and Prozesse (auch Threads)

## Ziele
- Systemabhängig 

> Alle Systeme 
- Fairness: Jeder Prozess soll einen fairen Anteil der CPU erhalten
- Balance: Alle Teile des Systems (CPU, I/O) möglichst effektiv auslasten

> Batch-Systeme
- Durchsatz: Maximiere Anzahl der Aufträge pro Zeit, Maß für Systemauslastung
- Ausführungszeit: Minimiere Ausführungszeit
- CPU Belegung: Konstante Belegung der CPU

> Interaktive Systeme
- Antwortzeit: Minimiere die Antwortzeit für einfehende Anfragen
- Proportionalität: Berücksichtige die Erwartungshaltung der Benutzer

> Echtzeit-Systeme
- Deadlines einhalten: Vermeide Datenverlust (Soft-Deadlines). Umgang mit Hard-Deadlines? 
- Vorhersagbarkeit: Vermeide Qualitätsverlust z.B. in Multimediasystemen

## Kriterien zur Auswahl von Prozessen
> Fairness vs. Priorität
- Die CPU sollte fair zwischen ähnlichen Prozessen (einer Klasse) aufgeteilt werden
- Jedoch sollten höher priorisierte Prozesse mehr CPU-Zeit erhalten

> I/O- vs. CPU-bound Prozesse
- Wie sollte die Prozessverteilung sein, um die CPU möglichst gut auszulasten? 

> Wartezeit
- Prozesse können verhungern, wenn sie nicht zu Einsatz kommen

> CPU-Belegung vs. Durchsatz
- Obwohl eine CPU dauerhaft belegt ist, muss es nicht heißen, dass ihr Durchsatz hoch ist
- Nach welcher Zeit sollte ein Prozess unterbrochen werden? 

## Scheduling-Klassen
- Nicht-unterbrechend (non-preemptive)
	- Prozesse werden so lange ausgeführt, bis sie blockieren oder freiwillig die CPU abgeben
	- ![[Pasted image 20260202181323.png|625]]
- Unterbrechend (preemptive)
	- Prozesse werden beim Auftreten von bestimmten Ereignissen (z.B. Timer-Interrupt) unterbrochen 
	- ![[Pasted image 20260202181336.png|625]]

## Scheduling-Strategien
> in Batch-Systemen
- First-Come-First-Served (FCFS), nicht unterbrechend
- Shortest Job First (SJF), nicht unterbrechend
- Shortest Remaining Time Next (SRTN), unterbrechend bei Ankunft neuer Prozesse

> in interaktiven Systemen
- Round-Robin Scheduling (RR), Zeitscheibenstrategie, unterbrechend nach Ablauf der Zeitscheibe
- Priority Scheduling, unterbrechend, höher priorisierte Prozesse haben Vorrang

> in Echtzeit-Systemen
- Earliest Deadline First (EDF), kann unterbrechend oder nicht-unterbrechend implementiert sein
- Rate-Monotonic Scheduling (RMS), unterbrechend

### Metriken zur Bewertung
- CPU Auslastung (allg. Ressourcenauslastung)
- Durchsatz
- Bearbeitungszeit := Rechenzeit + Wartezeit

### Batch-Systeme
#### FCFS
- non-preemptive
- Die CPU wird den Prozessen in der Reihenfolge zugewiesen, in der sie angefordert wird
- Verwaltet FIFO-Run-Queue (Ready-Queue) mit rechenwilligen Prozessen 
- Ein Prozess wird so lange ausgeführt, bis er blockiert oder freiwillig die CPU abgibt
- Sobald der rechende Prozess die CPU abgibt, wird der erste Prozess aus der Run-Queue aktiv

#### SJF
- non-preemptive
- Die CPU wird einem Prozess mit der kürzesten Rechenzeit zugewiesen
- SJF ist optimal, wenn alle Jobs am Anfang vorliegen und alle Rechenzeiten bekannt sind
- Problem: Ausführungszeit der nächsten Rechenphase muss abgeschätzt werden

#### SRTN
- preemptive
- unterbrechbare Variante von SJF
- Sobald ein neuer Prozess rechenwillig wird, wird seine Gesamt-Rechenzeit mit der verbleibenden Zeit des aktiven Prozesses verglichen
- Ist die Rechenzeit des neuen Prozesses kürzer, wurd der aktive Prozess unterbrochen

### Interaktive Systeme
#### RR
- Preemptive
- Benötigte Rechenzeit der Prozesse ist nicht vorab bekannt
- Rechenwillige Prozesse werden in einer FIFO Run-Queue (Ready-Queue) verwaltet
	- Neue Prozess ans Ende der Queue
- Jedem prozess wird ein Zeit-Quantum q zugeteilt
	- Die CPU wird den Prozessen spätestens nach Ablauf des Quantums q entzogen
	- Ein Prozess kann für das Zeit-Quantum q die CPU belegen, vorzeitige CPU-Freigabe, falls der Prozess blockiert oder freiwillig die CPU abgibt
- Strategische Frage hier: Wahl des Quantums q

#### Priority-Scheduling
- Preemptive
- Jedem Prozess wird eine Priorität zugewiesen
- Die CPU wird einem rechenwilligen prozess mit der höchsten Priorität zugewiesen
- Prozesse mit gleicher Priorität werden in einer Queue verwaltet
	- -> Eine Queue pro Prio
- Kontextwechsel sobald ein höher-priorisierter, rechenwilliger Prozess bereit ist
- Statische Priorisierung: Prioritäten ändern sich nicht
	- Risiko, dass Prozesse verhungern

- Dynamische Priorisierung: z.B. nach einem Timer-Interrupt neu berechnet
	- Prioritätsverringerung
		- Vermeiden, dass hoch-priorisierte Prozesse endlos laufen
		- `nice` Befehl in Unix Systemen verringert Prio explizit
	- Prioritätserhöhung
		- Vermeiden, dass niedrig-priorisierte Prozesse verhungern
	- I/O-Boost (z.B. unter Windows)
		- I/O-Bound Prozesse werden kurzzeitig stark bevorzugt

### Echtzeit-Systeme
- Zeit eine entscheidende Rolle
- weiche vs. harte Echtzeit-Systeme
	- Weiche: Es wird Toleriert, dass nicht alle Deadlines eingehalten werden (soft deadlines)
		- z.B. Verlieren von Paketen während einer Videokonferenz
	- Harte: Es existieren harte Deadlines, die eingehalten werden müssen (hard deadlines) 
		- z.B. Airbag muss sich innerhalb von einer bestimmten zeit nach dem Aufprall geöffnet haben
- Gegensätzliche Scheduling-Ziele bei unkritischen und zeitkritischen Prozessen
	- Unkritisch: Sollen nicht dauerhaft blockiert werden (verhungern)
	- Zeitkritisch: Müssen ihre Zeitvorgaben einhalten

#### EDF
- Die CPU wird dem Prozess mit der nächsten Deadline zugeordnet
- Interpretiert man Deadlines als Prioritäten, so entspricht EDF einem Prioritäten-basierten Scheduling-Verfahren

> Non-preemptive
- Der Prozess wird so lange ausgeführt, bis er blockiert oder freiwillig die CPU abgibt
- Neue Prozesse mit früheren Dadlines werden erst beim nächsten Kontextwechsel berücksichtigt

> Preemptive
- Der aktive Prozess wird unterbrochen, sobald ein Prozess mit einer früheren Deadline rechenwillig wird

#### RMS
- Schedulingverfahren für periodische Prozesse z.B. Ablaufsteuerungen in Anlagen
- Die Prozess-Prio wird in Abhängigkeit von der Periode zugeordnet
- Die Deadline entspricht dem Ende einer Periode, Prozess muss innerhalb der Periode beendet werden
- Prozesse mit der höchsten Frequenz (kleinste Periode) erhalten die niedrigste Prio
- Prio wird statisch vergeben
- RMS erlaubt es abzuschätzen, ob eine Echtzeit Anwendung auf einem bestimmten System ohne Deadline-Verletzung ausgeführt werden kann (Planbarkeit)


# Multilevel Scheduling
> Motivation
- Ggf. sind nicht alle rechenwilligen Prozesse bereits im Speicher eingelagert
- Das Einlagern von der Festplatte ist aufwendig und sollte vorab erfolgt sein

> Short-Term-Scheduler (STS)
- Preemptive vs. non-preemptive Scheduling von rechenwilligen Prozessen
- Auswahl eines geeigneten Prozesses aus der Run-Queue (Ready-Queue)
- Verwendet die bisher vorgestellten Verfahren
- Dispatcher ist i.d.R. Bestandteil des STS
- Wird sehr häufig aufgerugen

> Medium-Term-Scheduler (MTS)
- Entscheidet darüber, ob ein Prozess in den Speicher eingelagert werden soll
- Teil des Swapping-Mechanismus

> Long-Term-Scheduler (LTS)
- Ziel: guten Prozessmix erzielen, d.h. Mischung aus I/O-intensiven und rechenintensiven Prozessen
- Auswahl rechenwilliger neuer Aufträge und Einlagerung in den Arbeitsspeicher
- Scheduler steuert den Multiprogramming-Grad, d.h. wie viele Prozesse im Arbeitsspeicher liegen
- Wird aufgerufen, sobald ein neuer Prozess erzeugt wird
- Entscheidet darüber, ob der Prozess zur Ready-Queue hinzugefügt werden soll
- Sehr selten aufgerugen
- Nicht immer vorhanden, z.B. nicht unter Unix

![[Pasted image 20260202193850.png|446]]


# Scheduling unter Linux
- Threads unter Linux werden 1:1 auf Kernel-Level-Threads abgebildet -> "Tasks", Thread-basiertes Scheduling

- Linux unterscheidet zwischen drei Thread-Klassen
	1. Echtzeit-FIFO
		- Können von anderen Thread-Klassen nicht unterbrochen werden
	2. Echtzeit-Round-Robin
	3. Timesharing
		- Bis Kernel v2.6: O(1)-Scheduler basierend auf Priority Scheduling von 140 Prioritäten
			- Je höher die Prio, desto geringer ist das Quantum
		- Ab Kernel v2.6: Completely-Fair-Scheduler (CFS) basierend auf dem O(1)-Scheduler
			- Verwendet eine Red-Black Tree (anstatt Doubly-Linked Lists) basierte Run-Queue, sortiert nach bereits verbrauchter CPU-Rechenzeit (Prozess mit geringster Zeit wird gescheduled)
	
- Prioritäten
	- 0-99 reserviert für Echtzeit-Threads
	- 100-139 reserviert für Timesharing-Threads

# Multicore-/Multiprozessorscheduling
> Probleme
- Zuordnung von Prozessen zu einzelnen Kernen/Prozessoren
- Verschiedene Charakteristika der verschiedene Recheneinheiten
- Erhöhung der Komplexität des Schedulings erfordert Abwägung zwischen Qualität der Schedules und Schedulinggeschwindigkeit

> Der "einfachste" Fall
- Gegeben
	- N Prozesse ohne Abhängigkeiten mit Startzeiten $t_i = 0$ und Rechenzeiten $P_i$
	- M Prozessoren mit konstaten Charakteristika
- Gesucht
	- Schedule, der die Gesamtausführungszeit minimiert

- Für M=1: trivial, Prozesse einfach nacheinander ausführen
- Für M>1: äquivalent zu multiway number partitioning -> NP-hard (nicht deterministisch in polynomieller Zeit berechenbar)
- Realität: Abgesehen von M ist alles a priori unbekannt, Charakteristika ändern sich (z.B. variable Taktfrequenz) und Prozesse haben Abhängigkeiten -> Scheduling nur approximativ möglich

## Varianten
> Time Sharing
- Abwechselnde Nutzung von Ressource
- Langsamer Fortschritt für abhängige Prozesse

> Space Sharing
- Erlaubt abhängigen Prozessen direkten Austausch
- Abhängige Prozesse werden gemeinsam gescheduled und belegen die zugewiesene Ressourcen bis zum Terminieren (Partitionierung der Ressourcen)

- Vorteil: Keine Kontextwechsel während der Laufzeit
- Nachteil: mitunter hohe Wartezeiten, Anzahl anhängiger Prozesse limitiert auf Anzahl Ressourcen, meistens können nicht alle Ressourcen genutzt werden

> Gang Scheduling
- Kombination von Time und Space Sharing
- Abhängige Prozesse bilden Gang und werden als eine Einheit behandelt
- Gangs bekommen Zeitscheiben zugewiesen

## Warteschlangen
### Globale 
- Eine Warteschlange für alle CPUs
- Vorteile: 
	- Gute CPU Auslastung
	- Fair für alle Prozesse 
- Nachteile: 
	- Schlechte Skalierbarkeit durch lock contention
	- Schlechte Cache Lokalität

### Eine für jede CPU
- Statische Aufteilung der Prozesse auf CPUs
- Vorteile
	- Einfache Implementierung
	- Skalierbar (keine lock contention)
	- Bessere Cache Lokalität
- Nachteil
	- Ungleiche Auslastung der CPUs -> Unfair gegenüber Prozessen

### Hybride
- Verwendung einer globalen zusammen mit lokalen Warteschlangen
- Falls nötig werden Prozesse von einer lokalen Warteschlange in eine andere verschoben (Work stealing)
- Vorteil
	- Gute Auslastung
	- Prozessor-Affinität erlaubt Wiederverwendung von Daten im Cache
- Nachteil
	- komplizierte Implementierung
- ![[Pasted image 20260202204241.png|475]]

# Heterogenität von Prozessoren
- Die Ausführungszeit eines Prozesses hängt stark von der Wahl des Prozessors ab
- Gründe
	- Cache-Reuse: Wurde der Prozess bereits einmal auf dem Prozessor ausgeführt, kann er potentiell auf noch im Cache vorhandene Daten zurückgreifen
	- Hitze: Wärmeabgabe ist ein großes Problem in Prozessoren. Abhängig von den Operationen produziert ein Prozess mehr oder weniger Wärme. Ein Prozess mit hoher Wärmeabgabe sollte nicht auf einen bereits heißen Prozessor geschedulet werden
	- NUMA (Non-Uniform Memory Access): Die Zugriffszeit auf den Arbeitsspeicher ist nicht für alle Prozessoren identisch. Prozesse sollten möglichst nahe an dem von ihnen benötigten Speicher ausgeführt werden
	- Big-Little-Architecture: Aktuelle Entwicklung bei der zur Reduzierung des Stromverbrauchs verschiedene Prozessoren verbaut werden, die sich in ihrer Leistunsfähigkeit und somit ihrem Stromverbrauch unterscheiden. Zunehmend relevant für mobile Endgeräte