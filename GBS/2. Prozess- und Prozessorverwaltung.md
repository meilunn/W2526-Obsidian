# Definitionen
## Maschienenschnittstelle, Instruction Set Architecture (ISA)
- ISA ist Befehlsatz eines Prozessors
	- -> die Menge der Maschinenbefehle
- Unterscheidung zwischen RISC- (Reduced Instruction Set Computer) und CISC- (Complex Instruction Set Computer) Architekturen

## Assembler (Sprache)
- Ist einen maschienennahe (konkrete) Programmiersprache
- an die ISA der Zielarchitektur angelehnt
- Durch Verwendung von Namen und symbolischen Adressen wird die Nutzung der ISA vereinfacht

## Assembler (Programm)
- Systemprogramm, dass
	- Assemblerbefehle in Maschinencode transformiert und 
	- Symbolischen Namen Maschienenadressen zuweist und ein Objektprogramm erzeugt

#gbs/def Maschienenschnittstelle, ISA, Assembler 

# Vom Quellcode zum Programm
- Quellcode
	- bindet ggf weitere libraries mittels header
- Compiler
	- Preprocessor
		- bindet Dateien von header in code ein
	- Compiler
		- übersetzt von C in Assembler
- Assembler
	- Übersetzt von Maschinensprache in die ISA
- Linker (Binder) 
	- einzelne Module binden
	- produziert ELF Datei 
		- Executable linkable format
		- beginnt mit "7f" im hex Darstellung
- Loader (BS)
	- Liest ELF und lädt die Objekte in den zugehörigen Speicher


![[Pasted image 20251219121318.png|575]]

# [[GBS/1. Einführung#Prozesse|Prozesse]]

## Prozessor
![[Pasted image 20251219121940.png|500]]
- IOPL
	- in welchem betriebsmodus sich der prozessor gerade befindet
	- 2 bits -> [0, 3] darstellbar
	- verschiedene modus mit nummerierung 0-3

## Prozess im speicher
- code segment
	- read only da code unverändert sein soll
- data segment 
	- rodata
		- static constants
	- data
		- static local variablen
		- globale variablen im heap
	- heap
		- dynamically allocated
- stack segment
	- base pointer -> Anfang von jedem aufgerufenen Fkt (alte pos wird gemerkt)
		- stack frame ist von bp zu sp für jede Fkt
	- stack pointer -> wird verschoben jedes mal eine variable drauf geschoben wird
	- wächst von oben nach unten
	- lokale variblen
	- fktaufruf
	- mittlerweile fkt param nicht mehr auf den stack -> register 
- ![[Pasted image 20251219123451.png|525]]


## Prozesskontext im BS
- Abbild der CPU muss hinterlegt werden wenn einem prozess die CPU "weggenommen" wird -> bestimmte Datenstruktur

![[Pasted image 20251219123843.png|525]]
![[Pasted image 20251219123938.png|500]]

## Parallele Prozesse, Multiprogramming 
- System ist Menge von Prozessen
	- Prozesse können (quasi) parallel verarbeitet werden
	- Wechseln zwischen verschiedenen Prozessen (Scheduling)

> Warum Multiprogramming? 
- Prozesse können limitiert sein 
	- I/O bound
	- CPU bound
- -> Proz wechseln während man wartet

### Prozess-Zustände
> Zustände
- rechenwillig/ready
- rechnend/running
- wartend/blocked
- ausgelagert/swapped out

![[Pasted image 20251219124604.png|550]]
> Zustandsübergänge
- add
	- (init) -> ready
	- neu erzeigter Prozess wird zu der Menge der rechenwilligen Prozesse hinzugefügt
- assign
	- ready, running
	- als Folge eines Kontextwechsels wird dem Prozess die CPU zugeordner
- block
	- running -> blocked
	- aufgrund eines I/O-Aufrufs oder einer Synchronisationsoperation wird der Prozess auf wartend gesetzt
- ready
	- blocked -> ready 
	- nach Beendigung der angestoßenen Operation wechselt der Prozess in den Zustand rechenwillig
- retire
	- running -> (terminated)
	- der aktuell rechende Prozess terminiert
- swap out 
	- anywhere -> swapped out
	- Prozess wird auf die Festplatte ausgelagert
- swap in
	- swapped out -> ready/blocked
	- ausgelagerter Prozess wird in den Speicher gebracht

# Thread
- ein Thread wird betrachtet als eine Abstraktion eines physischen Prozessors
- repräsentieren nebenläufige Ausführungspfade eines Rechensystems
- Prozess besitzt mindestens einen Thread
- Multi-Threaded-Prozess besitzt mehrere Kontrollflüsse
- Threads eines Prozesses teilen sich dessen Adressraum
- Jeder Thread besitzt seinen eigenen Befehlszähler(instruction pointer)

![[Pasted image 20251219160838.png|400]]

#gbs/def 

# Prozess vs. Thread

- Prozess ist Programm in Ausführung
	- Benutzt Ressouren
	- Hat einen Kontrollfluss (definiert durch die Instruktion des Programms)
		- Ressourcen: CPU, Speicher etc
		- Kontrollfluss: Programmlogik, Schleifen, Bedingungen, Reihenfolge
- Prozess gruppiert und verwaltet Ressourcen
	- Adressraum inkl. Programmcode und Daten
	- Gemeinsam nutzbare Ressourcen für alle Threads eines Prozesses
- Thread definiert einen Kontrollfluss

- Thread-Kontext muss gesichert werden, sobald einem Thread die CPU entzogen wird (running -> blocked/ready)
	- program counter/instruction pointer
	- Registerwerte (z.B. Variablen etc.)
	- Stack zur Verwaltung von Unterprogrammaufrufen

| Per-process items                                                                                                                             | Per-thread items                               |
| --------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------- |
| Address space<br>Global variables<br>Open files<br>Child processes<br>Pending alarms<br>Signals and signal handlers<br>Accounting information | Program counter<br>Registers<br>Stack<br>State |
- Threads sind Aktivitätsträger
- Threads können auch in verschiedenen Zuständen sein (rechenwillig, rechnend, wartend, terminiert)
- ![[Pasted image 20251219161235.png|500]]


# Multi-Threading
## Warum? 
> Overhead
- Thread ist ein "lightweight" Prozess 
	- -> u.a. gemeinsamer Adressraum
- Einfache Kommunikation zwischen Threads eines Prozesses über gemeinsamen Adressraum
- Aufwand, einen Thread innerhalb eines Prozesses zu erstellen, ist wesentlich geringer als einen Prozess zu erzeugen
- Threads können wesentlich schneller ihren Kontext wechseln

> Performance
- Multi-Threading ermöglicht die quasi-parallele Ausführung von I/O-intensiven und CPU-intensiven Bereichen eines Prozesses
- Echt parallele Ausführung von Threads auf mehreren CPUs/Cores

## Beispiel: Multi-threaded Web-Server
- Ein Dispatcher-Thread erstellt auf Anfragen neue Server-Threads
- Mehrere Server-Threads (dynamisch erzeugt) bearbeiten eine Anfrage
- ![[Pasted image 20260201165453.png|525]]

- Dispatcher-Thread code:
```c
while (TRUE) {
	get_next_request (&buf);
	handoff_request (&buf);
}
```

- Worker-Threads code:
```c
while (TRUE) {
	wait_for_work (&buf);
	look_for_page_in_cache (&buf, &page);
	if (page_not_in_cache (&page));
		read_page_from_disk (&buf, &page);
	return_page (&page);
}
```


# Implementierung von Prozessen
- Kernel-Datenstruktur: **==Prozess Control Block==** (PCB)
	- Informationen für die ==Prozessverwaltung== (engl. process management)
		- Registerinhalte (inkl. Programm Counter, Stack Pointer, Statusregister (Flags), etc)
		- Prozess Zustand (z.B. wartent, rechnend, etc.)
			- Rechnend: Angabe der zugehörigen CPU
			- Wartend: Angabe des Ereignisses, auf das der Prozess wartet
		- Priorität
		- Eindeutige Process ID (PID)
		- Paren PID (PPID), Identität des Eltern-Prozesses
		- Process Group ID (PGID)
	
	- Informationen für die ==Speicherverwaltung== (memory management)
		- Pointer zu Code-, Daten-, und Stack-Segment
			- Beinhalten Angang und Größe der entsprechenden Segmente
	
	- Informationen für die ==Dateiverwaltung== (file management)
		- Root Verzeichnis
		- File Descriptors: Datenstrukturen, die geöffnete Dateien beschreiben
		- Benutzer (User) und Gruppen ID (UID, GID)

- Betriebssystem verwaltet alle Prozesse in Prozesstabellen
	- Eine Prozesstabelle ist eine verkettete Liste von PCBs
	- Separate Listen für die verschiedenen Prozesszustände
		- Run Queue: (Ready Queue) Linux rechenwillige Prozesse
		- Wait Queue: Verwaltet unter Linux wartende Prozesse
	- ![[Pasted image 20260201171239.png|550]]

## Prozesshierarchien (Unix)
- Nach Initialisierung aller Subsysteme des Kernels wird der erste Userspace-Process init erzeugt
- init erstellt einen Login-Prozess pro "Terminal", der das Einloggen ermöglicht
- der Login-Prozess erzeugt eine Shell, die wiederum weitere Prozesse erzeugen kann
- Jeder Prozess inkl seiner Kinder formen eine ==Prozessgruppe== (durch die PGID gekennzeichnet)
- Der Eltern-Prozess der Prozessgruppe bildet dabei den Prozessgruppen-Leader
- ![[Pasted image 20260201181639.png|475]]
- Der Eltern-Prozess kann mit den Systemcalls `wait`oder `waitpid` darauf warten, dass der Kind-Prozess terminiert
	- der Eltern-Prozess blockiert (einfügen in die Wait-Queue), bis der Kind-Prozess terminiert
	- Nach der Beendigung des Kindes, kann der Elternprozess dne Grund der Terminierung erfragen

### Zombies
- Wenn der Kind- vor dem Eltern-Prozess terminiert, entsteht ein sog. Zombie-Prozess
- Wenn ein Kind-Prozess so terminiert, dann wird
	- der Speicher des Prozesses de-allokiert und
	- der Exit-Status in den PCB geschrieben und bleibt erhalten: Zombie
- Sobald der Elternprozess den Exit-Status mit `wait(waitpid)` gelesen hat, wird der Zombie entfernt
- Zombie-Prozesse führen keinen Code mehr aus, belegen aber noch Platz in der Prozess-Tabelle

### Waisen
- orphans entstehen, wenn der Eltern- vor dem Kind-Prozess terminiert 
	- Kind-Prozess wird dann vom Init-Prozess adoptiert: PPID = 1
- Ein Waisen-Prozess kann anschließend zum Dämonen (Hintergrundprozess) werden
	- Dafür muss der Prozess sich von der Gruppen-ID und Benutzer-ID lösen
	- Gegebenenfalls alle offenen Filedeskriptoren (stdin, stdout, stderr) umleiten

>Bei Windows gibt es keine Prozesshierarchien
- Jedem Prozess wird bei Erzeugung ein Handle zugeordnet
- Kann an andere Prozesse übergeben werden

# BS-Dienste zur Prozessverwaltung
## zur Erzeugung von Prozessen
### Auslöser
> während der Systeminitialisierung
- Erzeugung von Vordergrundprozessen
	- Interagieren mit dem Benutzer
- von Hintergrundprozessen
	- Dämonen (daemons), spezielle Systemprozesse
	- Langlebige, passive Sysprozesse, die durch Ereignisse aktiviert werden

> durch andere Prozesse
- Auslagerung der Arbeit auf mehrere Prozesse 
- Beispiel: Server erzeugt für jede Client-Anfrage einen neuen Prozess

> durch Benutzer
- Ausführung eines Kommandos in der Shell; Doppelklick auch ein Icon

> durch das BS (Batch-Systeme)
- BS erstellt neue Prozesse, um eine Menge von Aufgaben oder Daten zu verarbeiten

### Dienste
- POSIX-Syscall: `pid_t fork()`
	- Eltern-Prozess erzeugt exakte Kopie (Kind-Prozess) inkl. Code, Data
	- Kopie des Speicherabbildes des Elternprozesses
		- Ausnahme copy-on-write (COW) Memory
	- Jeder Prozess erhält bei Erzeugung eine PID
	- Rückgabewert von fork unterscheidet Eltern- und Kindprozess
		- Elternprozess erhält die PID des Kindprozesses als Ergebis
		- Kindprozess erhält den Wert 0
			- Prozess kann die eigene PID erfragen mittels `getpid()`
			- Erfragen der PID des Elternprozesses mittels `getppid()`
	- Kind erbt unter anderem Filedeskriptoren zu offenen Dateien (z.B. stdin, stdout, stderr)
	- Falls der Kind-Prozess eigenen Code etc. benötige, so führt das Kind `exec{ve|le|...}` aus, um das Speichabbild zu überschreiben

- Beide Prozesse sind ==unabhängig== voneinander
	- Änderungen in einem nicht sichtbar für den anderen Prozess

## zur Terminierung von Prozessen
> Normale Beendigung (freiwillig)
- Das Programm terminiert durch das Aufrufen eines Systemcalls
- z.B. `void exit (int status), return status;` aus `main()`

> Vorzeitige Beendigung bei einem durch den Prozess erkannten Fehler (freiwillig)
- Beispiel: Das Programm erkennt, dass eine Datei nicht existiert
- Nutzung von `exit`wie obern, aber mit Fehlercode

> Vorzeitige Beendigung bei einem fatalem Fehler, erkannt durch das BS
- Verursacht durch einen Fehler im Programm
- Beispiel: Zugriff auf nicht existierenden Speicherbereich (Segmentation Fault)

> Terminierung durch einen anderen Prozess
- Beispiel: Senden einen Signals durch die Funktion `int kill (pid_t process_id, int signal);`

## Prozessorverwaltung
- Dispatcher: Realisiert Prozess-Zustandsübergänge von rechenwillig nach rechnend
	- die Ausführung von Prozess A muss unterbrochen werden, um die Ausführung eines anderen Prozesses B zu ermöglichen
- Scheduler: Wählt einen Prozess aus der Liste der rechenwilligen Prozesse (Run Queue)
	- Wahl des nächsten Prozesses durch Scheduling-Algorithmen getroffen
- ![[Pasted image 20260201184317.png|575]]

### Dispatcher
#### Aufgaben (meist Bestandteil des Schedulers)
- Bei den Zustandübergängen zwischen rechnend und rechenwillig finden Kontextwechsel (context switch) statt
- der Dispatcher implementiert den Wechsel
- Dispatcher entzieht den rechenden Prozess/Thread die CPU und teilt sie einem anderen rechenbereitem Prozess/Thread zu

1. **Ändert den Zustand** des rechenden Prozesses zu wartend oder rechenbereit
2. **Sichert den Kontext** des zuvor rechnenden Prozesses/Threads im PCB
3. **Lädt den Kontext** des rechenbereiten Prozesses/Threads
4. **Ändert den Zustand** des rechenbereiten Prozesses zu rechnend

![[Pasted image 20260201185337.png|425]]

- Beachte: Je umfangreicher ein PCB, desto teurer (d.h. aufwendiger) sind Kontextwechsel
- Threads haben einen kleineren Kontext im Vergleich zu Prozessen
	- Erinnerung: Prozesse gruppieren Ressourcen
	- Threads teilen sich Ressourcen mit dem Prozess (u.a. Adressraum)
- Ein Umschalten zwischen Threads ==im gleichen Prozess== erfolgt deshalb sehr schnell
- Wechseln zwischen Threads ==verschiedener Prozesse== ist genauso teuer wie ein Prozess-Wechsel

### Scheduler
- Treffen von strategischen Entscheidungen
	- Wechen Prozess oder Thread, wann und wie lange an die CPU binden
	- bei Multiprozessor-Systemen muss zusätzlich entschieden werden, an welche CPU der Prozess gebunden wird
- Ausnutzen von typischem Prozessverhalten
	- CPU-Nutzungs-Bursts wechseln sich mit I/O-Wartephasen ab
	- Berücksichtigung von CPU-limitierten- und I/O-limitierten-Prozessen

- Der Scheduler wird bei nachfolgenden Ereignissen aktiv und muss Entscheidungen treffen
	- Wenn ein neuer Prozess erzeugt wird (fork)
		- Soll der Eltern- oder der Kind-Prozess ausgeführt werden? 
	- Wenn ein Prozess terminiert
		- Was passiert wenn kein rechenwilliger Prozess existiert? 
	- Wenn ein prozess blockiert (aufgrund von I/O, Semaphoren, etc.)
		- Was passiert, wenn der blockierende Prozess eine Ressource belegt und der nächste Prozess diese Ressource benötigt?
	- Wenn ein Interrupt auftritt
		- Ein Interrupt ausgehend von einem I/O-Device, kann einen blockierten Prozess aufwecken
		- Eine Scheduling-Entscheidung kann bei jedem Timer-Interrupt getroffen werden

# Implementierung von Threads
- Threads werden im Addressraum eines Prozesses ausgeführt
	- Verwenden Synchronisationsmechanismen, um koordiniert auf gemeinsame Ressourcen zuzugreifen (und diese zu "schützen")
- Analog zu Prozessen können Threads in den folgenden Zuständen sein
- Implementierungsvarianten von Threads
	- User Space
	- Kernel Space
	- Hybride Varianten
- ![[Pasted image 20260201195034.png|278]]
	- ganzer Block ist ein Prozess

## User-Level-Threads
- BS-Kern kennt keine Threads, sondern nur Prozesse 
	- der BS-Kern verwaltet Single-threaded-Prozesse
- Realisierung von Threads und deren Verwaltung erfordert zusätzliche Operationen
	- Implementierung mittles eines Thread-Pakets
	- Bibliothek im User-Space, die für die Thread-Verwaltung zuständig ist
	- Ein Thread-Paket setzt auf einem beliebigem BS auf
- Das Thread-Paket stellt als Laufzeitsystem eine Menge von Operationen zur Verfügung
	- thread_create, thread_exit, thread_join, thread_yield, etc
- Das Laufzeitsystem verwaltet Threads im User-Space
	- eine Threadtabelle für jeden Prozess
- Prozessorzuteilung im BS-Kern erfolgt an Prozesse
	- Dass Thread-Paket implementiert einen eigene Thread-Scheduler
	- D.h. das System implementiert ein Two-Level-Scheduling-Verfahren

### Scheduling
- BS kat keine Kenntnis von User-Level Threads
- Scheduler wählt einen Prozess aus und gibt diesem ein Quantim an CPU-Zeit
- Laufzeitsystem des Prozesses wählt einen rechenwilligen Thread des Prozesses aus
- Ein Thread kann vom Laufzeitsystem nicht unterbrochen werden
	- Aber Threads können selbst durch den Aufruf der Funktion thread_yield die CPU abgeben
- ![[Pasted image 20260201195451.png|500]]

### Vorteile
- BS-unabhängig
- umschalten zwischen verschiedenen Threads sehr effizient -> keine Syscalls
- anwendungsspezifisches Scheduling Algorithmen

### Nachteile
- Blockieren eines Threads -> Blockiert den Prozessor
- ein blockierender Syscall eines Threads kann blockiert den gesamten Prozess, da BS nur Prozess kennt und nicht die Threads -> Nebenläufigkeit kann also doch nicht erreicht werden
- Threads können die CPU monopolisieren

## Kernel-Level Threads
- BS-Kern verwaltet Threads selbst
	- Der BS-Kern hält eine Threadtabelle für alle Threads (im Kern)
	- Thread-Operationen führen zu einem Trap in den Kern
		- thread_create, thread_exit, etc.
		- Wechsel von User zu Kernel Mode
	- Systemaufrufe bei Erzeugung bzw. Terminierung von Threads
	- Nicht mehr so leichtgewichtig verglichen mit Prozessen
- ![[Pasted image 20260201202542.png|525]]

- BS-Scheduler wählt einen rechenwilligen Thread
- BS kontolliert die CPU Zuteilung an Threads

> Overhead minimieren
-  Scheduling-Entscheidungen: Kernel sollte die Thread-Zugehörigkeit zu Prozessen berücksichtigen, um den Overhead für einen Kontextwechsel zu verringern

> Blockierende I/O-Operationen
- Wenn ein Kernel-Level Thread blockiert, so kann die CPU einem anderen Thread des gleichen Prozesses zugeordnet werden, ohne den gesamten Prozess aufzuhalten

## Hybride Implementierung
- Der BS-Kern verwaltet sogenannte Kernel-Threads
- Das BS kennt nur Kernel-Threads: das Scheduling erfolgt für Kernel-Threads
- n Threads im User-Space werden auf m Kernel-Threads abgebildet (n:m Abbildung)
- ![[Pasted image 20260201203015.png|475]]

## Unix-Threads
- UNIX-basierte Systeme unterstützen Kernel-Level Threads

> LinuxThreads: Erste Thread Implementierung unter Linux
- Thread-Erzeugung mit dem Syscall `clone()`
- Threads teilen sich den Adressraum, Datei-Deskriptoren, Signale, etc.
- Jedoch besitzen alle Threads unterschiedliche PIDs und PPIDs
- Benötigen einen zusätzlichen Manager-Thread zur Erzeugung und Terminierung von Threads

> Native POSIX Thread Library (ab Linux kernel v2.6)
- Erweiterung des Syscalls clone (u.A. durch das Flag CLONE_THREAD)
- POSIX Thread Schnittstelle abstrahiert den Systemcall
- Implementiert eine 1:1 Abbildung von User-Space-Threads auf Kernel-Level Threads

> Beispiel: Java Threads (JVM Verwendet NPTL)
- Jeder Java-Thread gehört dem Java-Virtual-Machine Prozess an
- Jeder Java Thread wird 1:1 auf einen Kernel-Level-Thread abgebidet

## Beispiel: Thread-Erzeugung unter Linux
- Der Main-Thread erstellt einen zweiten Thread mit `pthread_create`
	- Der neue Thread führt die übergebene Funktion `thread_func` aus
	- Der String "hello world" wird `thread_func` als Argument übergeben

- Der erzeugte THread führt die Funktion aus und beendet sich mit `pthread_exit` 
	- Alternativ, kann der Rückgabewert auch mit return übergeben werden
	- Achtung: Ausführen von `exit` beendet den gesamten Prozess

- `pthread_join` wartet auf die Terminierung und Rückgabewert des Threads
	- Andernfalls entsteht ein Pendant zu einem Zombie-Prozess

# Linux: Prozesse vs. Threads
- Linux nutzt ein gemeinsames Basiskonstrukt: "Tasks"
	- Tasks sind Instanzen, die von Scheduler gesteuert werden

- Prozesse und Threads werden beide auf Tasks abgebildet
	- Linux realisiert Kernel-Level Threads

- Unterscheidung zwischen Prozessen und Threads durch den Grad der Isolation voneinander bzw. der gemeinsamen Nutzung von Ressourcen
	- Parameter steuern, welche Ressourcen sich zwei Tasks teilen 
	- Individuell für verschiedene Ressourcen einstellbar
	
	- Extrem 1: keine geteilten Ressourcen -> Prozesse
	- Extrem 2: quasi alle Ressourcen geteilt -> Threads

- `fork()` und `pthread_create()` werden auf denselben Syscall abgebildet: `clone()`
	- u.A. Flags als Parameter für clone
		- CLONE_FILES - file descriptor table
		- CLONE_FS - file system (e.g. working directory, umask)
		- CLONE_IO - IO context (SDD/HDD Zugriff)
		- CLONE_PARENT - gleicher Elternprozess
		- CLONE_PID - gleiche PID
		- CLONE_VM - virtueller Speicher
		- CLONE_NEW - unabhängige Namensräume


# Scheduling
- Vergabe der CPU and Prozesse (auch Threads)

## Ziele
- Systemabhängig 

> Alle Systeme 
- Fairness: Jeder Prozess soll einen fairen Anteil der CPU erhalten
- Balance: Alle Teile des Systems (CPU, I/O) möglichst effektiv auslasten

> Batch-Systeme
- Durchsatz: Maximiere Anzahl der Aufträge pro Zeit, Maß für Systemauslastung